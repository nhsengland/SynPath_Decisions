{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06512d-9341-479d-8ec2-1760bb3250db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1241: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\xinwe\\AppData\\Local\\Temp\\ipykernel_11700\\2618614728.py:99: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['_vitals_score_raw'].fillna(known_median, inplace=True)\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 200\u001b[0m\n\u001b[0;32m    184\u001b[0m     weights \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplexity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.30\u001b[39m,\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macuity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.50\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    190\u001b[0m     }\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# elif which == 'historic':\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m#     weights = {\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m#         'complexity': 0.25,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m#         'admission': 0.125\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m ranked \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mcda_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_within_Speciality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m ordered \u001b[38;5;241m=\u001b[39m rank_within_all_specialties(ranked)\n\u001b[0;32m    203\u001b[0m save_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcda_ranked_patients_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhich\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 125\u001b[0m, in \u001b[0;36mcompute_mcda_scores\u001b[1;34m(df, weights, vitals_map, normalize_within_Speciality, patient_id, age_col, gender_col, complexity_col, acuity_col, primarydiagnosis_col, department_col, vitals_col, waiting_col, admission_col, nextAction_col, blocker_col, dischargedependence_col)\u001b[0m\n\u001b[0;32m    115\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_admit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeciality\u001b[39m\u001b[38;5;124m'\u001b[39m)[admission_col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m s: normalize_series(s))\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    117\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMCDA_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    118\u001b[0m     weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplexity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_complexity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    119\u001b[0m     weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macuity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_acuity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m     weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_admit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    123\u001b[0m )\n\u001b[1;32m--> 125\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcda_rank_within_Speciality\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpeciality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMCDA_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtie_breaker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[[acuity_col, complexity_col, vitals_col]]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcuity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[acuity_col]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|Complexity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[complexity_col]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|Vitals=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[vitals_col]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    131\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_vitals_score_raw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_complexity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_acuity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_wait\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm_admit\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\generic.py:6665\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6660\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6661\u001b[0m     ]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6664\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6665\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6666\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:449\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    447\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    782\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    788\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[0;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:145\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NHS MCDA for patient pathway prioritization\n",
    "\n",
    "This script implements a small, flexible Multi-Criteria Decision Analysis (MCDA)\n",
    "for ranking patients within each Speciality (department).\n",
    "\n",
    "Primary rule from user:\n",
    "  1) Group (primary key): Speciality\n",
    "  2) Within each Speciality, rank using criteria in this order (but implemented\n",
    "     as a weighted MCDA so weights can be tuned):\n",
    "       - Complexity (numerical) — larger => higher priority\n",
    "       - Acuity (1..5, higher = worse) — larger => higher priority\n",
    "       - VitalsTrend (categorical) — priority order: Deteriorating > Stable > Improving\n",
    "\n",
    "Features:\n",
    "  - Normalises numeric values (optionally within each Speciality)\n",
    "  - Maps VitalsTrend to an ordinal score\n",
    "  - Allows adjustable weights for each criterion\n",
    "  - Handles missing data sensibly\n",
    "  - Returns a ranked DataFrame per Speciality and an overall ordering (Speciality groups preserved)\n",
    "\n",
    "Usage example included at bottom.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEFAULT_VITALS_ORDER = {\n",
    "    'Deteriorating': 1.0,\n",
    "    'Stable': 0.5,\n",
    "    'Improving': 0.0\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Min-max normalize a pandas Series to [0,1]. If constant, returns 0.5 for all.\n",
    "    NaNs are left as NaN.\n",
    "    \"\"\"\n",
    "    valid = s.dropna()\n",
    "    if valid.empty:\n",
    "        return s\n",
    "    mn = valid.min()\n",
    "    mx = valid.max()\n",
    "    if mn == mx:\n",
    "        # constant series; return 0.5 for known values\n",
    "        out = s.copy()\n",
    "        out.loc[s.notna()] = 0.5\n",
    "        return out\n",
    "    return (s - mn) / (mx - mn)\n",
    "\n",
    "\n",
    "def compute_mcda_scores(\n",
    "    df: pd.DataFrame,\n",
    "    weights: Dict[str, float] = None,\n",
    "    vitals_map: Dict[str, float] = None,\n",
    "    normalize_within_Speciality: bool = True,\n",
    "    patient_id: str = 'pseudo_patient_id',\n",
    "    age_col: str = 'age',\n",
    "    gender_col: str = 'sex',\n",
    "    complexity_col: str = 'Complexity',\n",
    "    acuity_col: str = 'Acuity',\n",
    "    primarydiagnosis_col: str = 'Primary Diagnosis Summary',\n",
    "    department_col: str = 'Speciality',\n",
    "    vitals_col: str = 'Vitals Trend',\n",
    "    waiting_col: str = 'Waiting Time (days)',\n",
    "    admission_col: str = 'Time since Admission (days)',\n",
    "    nextAction_col: str = 'nextAction',\n",
    "    blocker_col: str = 'blocker',\n",
    "    dischargedependence_col: str = 'Discharge Dependence'\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = df.copy()\n",
    "    required = ['Speciality', complexity_col, acuity_col, waiting_col, admission_col, vitals_col]\n",
    "\n",
    "    # Find missing columns\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "\n",
    "    # If any missing, create them with default value 0\n",
    "    for c in missing:\n",
    "        df[c] = 0\n",
    "\n",
    "    # Ensure all expected keys are present (missing keys get 0.0)\n",
    "    for k in ['complexity', 'acuity', 'waiting']:\n",
    "        weights.setdefault(k, 0.0)\n",
    "\n",
    "    w_total = sum(weights.values())\n",
    "    if w_total == 0:\n",
    "        raise ValueError('Sum of weights must be > 0')\n",
    "    weights = {k: v / w_total for k, v in weights.items()}\n",
    "\n",
    "    if vitals_map is None:\n",
    "        vitals_map = DEFAULT_VITALS_ORDER\n",
    "\n",
    "    df['_vitals_score_raw'] = df[vitals_col].map(vitals_map)\n",
    "    if df['_vitals_score_raw'].isna().any():\n",
    "        known_median = df['_vitals_score_raw'].median(skipna=True)\n",
    "        df['_vitals_score_raw'].fillna(known_median, inplace=True)\n",
    "\n",
    "    if normalize_within_Speciality:\n",
    "        norm_complexity = df.groupby('Speciality')[complexity_col].transform(lambda s: normalize_series(s))\n",
    "        norm_acuity = df.groupby('Speciality')[acuity_col].transform(lambda s: normalize_series(s))\n",
    "        norm_wait = df.groupby('Speciality')[waiting_col].transform(lambda s: normalize_series(s))\n",
    "        norm_admit = df.groupby('Speciality')[admission_col].transform(lambda s: normalize_series(s))\n",
    "    else:\n",
    "        norm_complexity = normalize_series(df[complexity_col])\n",
    "        norm_acuity = normalize_series(df[acuity_col])\n",
    "        norm_wait = normalize_series(df[waiting_col])\n",
    "        norm_admit = normalize_series(df[admission_col])\n",
    "\n",
    "    df['_norm_complexity'] = df.groupby('Speciality')[complexity_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "    df['_norm_acuity'] = df.groupby('Speciality')[acuity_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "    df['_norm_wait'] = df.groupby('Speciality')[waiting_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "    df['_norm_admit'] = df.groupby('Speciality')[admission_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "\n",
    "    df['MCDA_score'] = (\n",
    "        weights['complexity'] * df['_norm_complexity'] +\n",
    "        weights['acuity'] * df['_norm_acuity'] +\n",
    "        weights['vitals'] * df['_vitals_score_raw'] +\n",
    "        weights['waiting'] * df['_norm_wait'] +\n",
    "        weights['admission'] * df['_norm_admit']\n",
    "    )\n",
    "\n",
    "    df['mcda_rank_within_Speciality'] = df.groupby('Speciality')['MCDA_score'].rank(method='first', ascending=False).astype(int)\n",
    "\n",
    "    df['tie_breaker'] = df[[acuity_col, complexity_col, vitals_col]].apply(\n",
    "        lambda row: f\"Acuity={row[acuity_col]}|Complexity={row[complexity_col]}|Vitals={row[vitals_col]}\", axis=1\n",
    "    )\n",
    "\n",
    "    df.drop(columns=['_vitals_score_raw', '_norm_complexity', '_norm_acuity', '_norm_wait', '_norm_admit'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def rank_within_all_specialties(df_out: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame ordered first by Speciality (alphabetical) and then by mcda_rank_within_Speciality.\n",
    "    If you prefer a different Speciality order, reorder 'Speciality' before calling this function.\n",
    "    \"\"\"\n",
    "    df = df_out.copy()\n",
    "    df.sort_values(['Speciality', 'mcda_rank_within_Speciality'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Example usage (run as script or import functions)\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # Load ScenarioA data\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    data_dir = Path('../data/scenarioA/')\n",
    "    paths = {\n",
    "        \"current\": data_dir / \"ScenarioA_patients_current.csv\",\n",
    "        \"coming\": data_dir / \"ScenarioA_patients_coming.csv\",\n",
    "        \"historic\": data_dir / \"ScenarioA_patients_historic.csv\"\n",
    "    }\n",
    "\n",
    "    dfs = {k: pd.read_csv(v) for k, v in paths.items()}\n",
    "    for name, df in dfs.items():\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        dfs[name] = df\n",
    "\n",
    "    current = dfs[\"current\"].copy()\n",
    "    coming = dfs[\"coming\"].copy()\n",
    "    historic = dfs[\"historic\"].copy()\n",
    "\n",
    "    # Choose which dataset to run: 'current', 'coming', or 'historic'\n",
    "    which = 'current'\n",
    "    input_df = dfs[which].copy()\n",
    "\n",
    "    if which == 'current':\n",
    "        weights = {\n",
    "            'complexity': 0.20,\n",
    "            'acuity': 0.30,\n",
    "            'vitals': 0.30,\n",
    "            'waiting': 0.10,\n",
    "            'admission': 0.10\n",
    "        }\n",
    "    elif which == 'coming':\n",
    "        weights = {\n",
    "            'complexity': 0.30,\n",
    "            'acuity': 0.50,\n",
    "            'waiting': 0.20,\n",
    "            'vitals': 0,\n",
    "            'admission':0,\n",
    "        }\n",
    "    # elif which == 'historic':\n",
    "    #     weights = {\n",
    "    #         'complexity': 0.25,\n",
    "    #         'acuity': 0.25,\n",
    "    #         'vitals': 0.25,\n",
    "    #         'waiting': 0.125,\n",
    "    #         'admission': 0.125\n",
    "    #     }\n",
    "\n",
    "    ranked = compute_mcda_scores(input_df, weights=weights, normalize_within_Speciality=True)\n",
    "    ordered = rank_within_all_specialties(ranked)\n",
    "\n",
    "    save_name = f'mcda_ranked_patients_{which}.csv'\n",
    "    ordered.to_csv(save_name, index=False)\n",
    "    print(ordered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1721cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pseudo_patient_id  age sex  Complexity  Acuity Primary Diagnosis Summary  \\\n",
      "0            SP0978   95   F        1.48       5                   K20-K31   \n",
      "1            SP0914   52   F        1.37       5                   K55-K64   \n",
      "2            SP0994   72   F        1.43       4                   K90-K93   \n",
      "3            SP0921   50   F        1.25       4                   K50-K52   \n",
      "4            SP0935   23   M        0.95       5                   K20-K31   \n",
      "\n",
      "          Speciality  Waiting Time (days) Discharge Dependence  \\\n",
      "0  Gastronenterology                   29                  Low   \n",
      "1  Gastronenterology                    3                  Low   \n",
      "2  Gastronenterology                   10                 High   \n",
      "3  Gastronenterology                   55                  Low   \n",
      "4  Gastronenterology                   17                  Low   \n",
      "\n",
      "   Time since Admission (days) Vitals Trend  MCDA_score  \\\n",
      "0                          0.0       Stable    0.826131   \n",
      "1                          0.0       Stable    0.764130   \n",
      "2                          0.0       Stable    0.665731   \n",
      "3                          0.0       Stable    0.652261   \n",
      "4                          0.0       Stable    0.641244   \n",
      "\n",
      "   mcda_rank_within_Speciality                             tie_breaker  \n",
      "0                            1  Acuity=5|Complexity=1.48|Vitals=Stable  \n",
      "1                            2  Acuity=5|Complexity=1.37|Vitals=Stable  \n",
      "2                            3  Acuity=4|Complexity=1.43|Vitals=Stable  \n",
      "3                            4  Acuity=4|Complexity=1.25|Vitals=Stable  \n",
      "4                            5  Acuity=5|Complexity=0.95|Vitals=Stable  \n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DEFAULT_VITALS_ORDER = {\n",
    "    'Deteriorating': 1.0,\n",
    "    'Stable': 0.5,\n",
    "    'Improving': 0.0\n",
    "}\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def _keyize(name: str) -> str:\n",
    "    \"\"\"Lowercase, strip, collapse spaces/punct to create a matching key.\"\"\"\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    return \"\".join(ch for ch in name.strip().lower() if ch.isalnum())\n",
    "\n",
    "def _apply_column_aliases(df: pd.DataFrame, alias_map: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map many possible input column spellings to canonical names present in alias_map values.\n",
    "    If a canonical column already exists, it is left untouched.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Build lookup from normalized current col names -> actual col name\n",
    "    current = {_keyize(c): c for c in df.columns}\n",
    "\n",
    "    for variants, canonical in alias_map.items():\n",
    "        # variants can be a list/tuple of possible keys\n",
    "        if isinstance(variants, (list, tuple, set)):\n",
    "            found = None\n",
    "            for v in variants:\n",
    "                vkey = _keyize(v)\n",
    "                if vkey in current:\n",
    "                    found = current[vkey]\n",
    "                    break\n",
    "        else:\n",
    "            vkey = _keyize(variants)\n",
    "            found = current.get(vkey, None)\n",
    "\n",
    "        if found is not None and canonical not in df.columns:\n",
    "            df.rename(columns={found: canonical}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def normalize_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Min-max normalize a pandas Series to [0,1]. If constant, returns 0.5 for all; NaNs preserved.\"\"\"\n",
    "    valid = s.dropna()\n",
    "    if valid.empty:\n",
    "        return s\n",
    "    mn = valid.min()\n",
    "    mx = valid.max()\n",
    "    if mn == mx:\n",
    "        out = s.copy()\n",
    "        out.loc[s.notna()] = 0.5\n",
    "        return out\n",
    "    return (s - mn) / (mx - mn)\n",
    "\n",
    "# ---------- Core MCDA ----------\n",
    "def compute_mcda_scores(\n",
    "    df: pd.DataFrame,\n",
    "    weights: Dict[str, float] = None,\n",
    "    vitals_map: Dict[str, float] = None,\n",
    "    normalize_within_Speciality: bool = True,\n",
    "    patient_id: str = 'pseudo_patient_id',\n",
    "    age_col: str = 'age',\n",
    "    gender_col: str = 'sex',\n",
    "    complexity_col: str = 'Complexity',\n",
    "    acuity_col: str = 'Acuity',\n",
    "    primarydiagnosis_col: str = 'Primary Diagnosis Summary',\n",
    "    department_col: str = 'Speciality',\n",
    "    vitals_col: str = 'Vitals Trend',\n",
    "    waiting_col: str = 'Waiting Time (days)',\n",
    "    admission_col: str = 'Time since Admission (days)',\n",
    "    nextAction_col: str = 'nextAction',\n",
    "    blocker_col: str = 'blocker',\n",
    "    dischargedependence_col: str = 'Discharge Dependence'\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # 1) Standardize incoming columns (handles spaces/US-UK spellings/etc.)\n",
    "    alias_map = {\n",
    "        # department\n",
    "        ('speciality', 'specialty', 'department', 'dept'): department_col,\n",
    "        # vitals trend\n",
    "        ('vitalstrend', 'vitals trend', 'vitals', 'trend'): vitals_col,\n",
    "        # waiting days\n",
    "        ('waitingtime(days)', 'waitingtime', 'waitingdays', 'waitdays'): waiting_col,\n",
    "        # admission days\n",
    "        ('timesinceadmission(days)', 'timesinceadmission', 'admissiondays', 'admitdays'): admission_col,\n",
    "        # complexity / acuity\n",
    "        ('complexity',): complexity_col,\n",
    "        ('acuity',): acuity_col,\n",
    "        # others used elsewhere\n",
    "        ('primarydiagnosissummary', 'primarydiagnosis', 'diagnosis', 'dx'): primarydiagnosis_col,\n",
    "        ('dischargedependence', 'discharge dependence'): dischargedependence_col,\n",
    "        ('nextaction',): nextAction_col,\n",
    "        ('blocker', 'block'): blocker_col,\n",
    "        ('sex', 'gender'): gender_col,\n",
    "        ('age',): age_col,\n",
    "        ('pseudopatientid', 'patientid', 'id'): patient_id,\n",
    "    }\n",
    "    df = _apply_column_aliases(df, alias_map)\n",
    "\n",
    "    # 2) Create missing required columns with safe defaults\n",
    "    df = df.copy()\n",
    "    # Required for scoring:\n",
    "    required = [department_col, complexity_col, acuity_col, waiting_col, admission_col, vitals_col]\n",
    "\n",
    "    # Decide defaults by type\n",
    "    default_values: Dict[str, Any] = {\n",
    "        department_col: \"Unknown\",\n",
    "        complexity_col: 0.0,\n",
    "        acuity_col: 0.0,\n",
    "        waiting_col: 0.0,\n",
    "        admission_col: 0.0,\n",
    "        vitals_col: \"Stable\",   # Safe neutral-ish default\n",
    "    }\n",
    "\n",
    "    for c in required:\n",
    "        if c not in df.columns:\n",
    "            df[c] = default_values[c]\n",
    "\n",
    "    # 3) Coerce numeric columns to numeric (errors='coerce' -> NaN -> later filled/handled)\n",
    "    for c in [complexity_col, acuity_col, waiting_col, admission_col]:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # 4) Weights & vitals map defaults\n",
    "    if weights is None:\n",
    "        weights = dict(complexity=0.25, acuity=0.25, vitals=0.25, waiting=0.125, admission=0.125)\n",
    "    # ensure all keys present\n",
    "    for k in ['complexity', 'acuity', 'vitals', 'waiting', 'admission']:\n",
    "        weights.setdefault(k, 0.0)\n",
    "\n",
    "    w_total = sum(weights.values())\n",
    "    if w_total == 0:\n",
    "        # If user gives all zeros, fall back to equal non-zero weights on present criteria\n",
    "        weights = dict(complexity=0.25, acuity=0.25, vitals=0.25, waiting=0.125, admission=0.125)\n",
    "        w_total = 1.0\n",
    "    weights = {k: v / w_total for k, v in weights.items()}\n",
    "\n",
    "    if vitals_map is None:\n",
    "        vitals_map = DEFAULT_VITALS_ORDER\n",
    "\n",
    "    # 5) Vitals mapping -> numeric score, fill unknowns with median of known\n",
    "    df['_vitals_score_raw'] = df[vitals_col].map(vitals_map)\n",
    "    if df['_vitals_score_raw'].isna().any():\n",
    "        known_median = df['_vitals_score_raw'].median(skipna=True)\n",
    "        # If still NaN (e.g., no known), fall back to 0.5\n",
    "        if pd.isna(known_median):\n",
    "            known_median = 0.5\n",
    "        df['_vitals_score_raw'] = df['_vitals_score_raw'].fillna(known_median)\n",
    "\n",
    "    # 6) Normalization (within department or global)\n",
    "    if normalize_within_Speciality:\n",
    "        group = df.groupby(department_col, dropna=False)\n",
    "        norm_complexity = group[complexity_col].transform(normalize_series)\n",
    "        norm_acuity     = group[acuity_col].transform(normalize_series)\n",
    "        norm_wait       = group[waiting_col].transform(normalize_series)\n",
    "        norm_admit      = group[admission_col].transform(normalize_series)\n",
    "    else:\n",
    "        norm_complexity = normalize_series(df[complexity_col])\n",
    "        norm_acuity     = normalize_series(df[acuity_col])\n",
    "        norm_wait       = normalize_series(df[waiting_col])\n",
    "        norm_admit      = normalize_series(df[admission_col])\n",
    "\n",
    "    # Fill NaNs from normalization (e.g., all-NaN/constant groups) with neutral 0.5\n",
    "    df['_norm_complexity'] = norm_complexity.fillna(0.5)\n",
    "    df['_norm_acuity']     = norm_acuity.fillna(0.5)\n",
    "    df['_norm_wait']       = norm_wait.fillna(0.5)\n",
    "    df['_norm_admit']      = norm_admit.fillna(0.5)\n",
    "\n",
    "    # 7) MCDA score\n",
    "    df['MCDA_score'] = (\n",
    "        weights['complexity'] * df['_norm_complexity'] +\n",
    "        weights['acuity']     * df['_norm_acuity'] +\n",
    "        weights['vitals']     * df['_vitals_score_raw'] +\n",
    "        weights['waiting']    * df['_norm_wait'] +\n",
    "        weights['admission']  * df['_norm_admit']\n",
    "    )\n",
    "\n",
    "    # 8) Rank within department\n",
    "    df['mcda_rank_within_Speciality'] = (\n",
    "        df.groupby(department_col)['MCDA_score']\n",
    "          .rank(method='first', ascending=False)\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # 9) Tie-breaker label (robust to missing)\n",
    "    def _fmt_tie(row):\n",
    "        a = row.get(acuity_col, np.nan)\n",
    "        c = row.get(complexity_col, np.nan)\n",
    "        v = row.get(vitals_col, \"Unknown\")\n",
    "        return f\"Acuity={a}|Complexity={c}|Vitals={v}\"\n",
    "\n",
    "    df['tie_breaker'] = df.apply(_fmt_tie, axis=1)\n",
    "\n",
    "    # 10) Cleanup helper cols\n",
    "    df.drop(columns=['_vitals_score_raw', '_norm_complexity', '_norm_acuity', '_norm_wait', '_norm_admit'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def rank_within_all_specialties(df_out: pd.DataFrame, department_col: str = 'Speciality') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame ordered first by department_col (alphabetical)\n",
    "    and then by mcda_rank_within_Speciality.\n",
    "    \"\"\"\n",
    "    df = df_out.copy()\n",
    "    if department_col not in df.columns:\n",
    "        # Graceful fallback\n",
    "        department_col = next((c for c in df.columns if _keyize(c) in ('speciality','specialty','department')), 'Speciality')\n",
    "        if department_col not in df.columns:\n",
    "            df[department_col] = \"Unknown\"\n",
    "    df.sort_values([department_col, 'mcda_rank_within_Speciality'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Example usage\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    from pathlib import Path\n",
    "\n",
    "    data_dir = Path('../data/scenarioA/')\n",
    "    paths = {\n",
    "        \"current\":  data_dir / \"ScenarioA_patients_current.csv\",\n",
    "        \"coming\":   data_dir / \"ScenarioA_patients_coming.csv\",\n",
    "        \"historic\": data_dir / \"ScenarioA_patients_historic.csv\"\n",
    "    }\n",
    "\n",
    "    dfs = {k: pd.read_csv(v) for k, v in paths.items()}\n",
    "\n",
    "    # Trim whitespace in headers\n",
    "    dfs = {k: df.rename(columns={c: c.strip() for c in df.columns}) for k, df in dfs.items()}\n",
    "\n",
    "    which = 'coming'  # 'current' | 'coming' | 'historic'\n",
    "    input_df = dfs[which].copy()\n",
    "\n",
    "    if which == 'current':\n",
    "        weights = {'complexity': 0.20, 'acuity': 0.30, 'vitals': 0.30, 'waiting': 0.10, 'admission': 0.10}\n",
    "    elif which == 'coming':\n",
    "        weights = {'complexity': 0.30, 'acuity': 0.50, 'waiting': 0.20, 'vitals': 0.0, 'admission': 0.0}\n",
    "    else:  # 'historic' or anything else\n",
    "        weights = {'complexity': 0.25, 'acuity': 0.25, 'vitals': 0.25, 'waiting': 0.125, 'admission': 0.125}\n",
    "\n",
    "    ranked = compute_mcda_scores(input_df, weights=weights, normalize_within_Speciality=True)\n",
    "    ordered = rank_within_all_specialties(ranked, department_col='Speciality')\n",
    "\n",
    "    save_name = f'mcda_ranked_patients_{which}.csv'\n",
    "    ordered.to_csv(save_name, index=False)\n",
    "    print(ordered.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tkinter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
