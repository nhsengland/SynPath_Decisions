{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06512d-9341-479d-8ec2-1760bb3250db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NHS MCDA for patient pathway prioritization\n",
    "\n",
    "This script implements a small, flexible Multi-Criteria Decision Analysis (MCDA)\n",
    "for ranking patients within each Speciality (department).\n",
    "\n",
    "Primary rule from user:\n",
    "  1) Group (primary key): Speciality\n",
    "  2) Within each Speciality, rank using criteria in this order (but implemented\n",
    "     as a weighted MCDA so weights can be tuned):\n",
    "       - Complexity (numerical) — larger => higher priority\n",
    "       - Acuity (1..5, higher = worse) — larger => higher priority\n",
    "       - VitalsTrend (categorical) — priority order: Deteriorating > Stable > Improving\n",
    "\n",
    "Features:\n",
    "  - Normalises numeric values (optionally within each Speciality)\n",
    "  - Maps VitalsTrend to an ordinal score\n",
    "  - Allows adjustable weights for each criterion\n",
    "  - Handles missing data sensibly\n",
    "  - Returns a ranked DataFrame per Speciality and an overall ordering (Speciality groups preserved)\n",
    "\n",
    "Usage example included at bottom.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEFAULT_VITALS_ORDER = {\n",
    "    'Deteriorating': 1.0,\n",
    "    'Stable': 0.5,\n",
    "    'Improving': 0.0\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Min-max normalize a pandas Series to [0,1]. If constant, returns 0.5 for all.\n",
    "    NaNs are left as NaN.\n",
    "    \"\"\"\n",
    "    valid = s.dropna()\n",
    "    if valid.empty:\n",
    "        return s\n",
    "    mn = valid.min()\n",
    "    mx = valid.max()\n",
    "    if mn == mx:\n",
    "        # constant series; return 0.5 for known values\n",
    "        out = s.copy()\n",
    "        out.loc[s.notna()] = 0.5\n",
    "        return out\n",
    "    return (s - mn) / (mx - mn)\n",
    "\n",
    "\n",
    "def compute_mcda_scores(\n",
    "    df: pd.DataFrame,\n",
    "    weights: Dict[str, float] = None,\n",
    "    vitals_map: Dict[str, float] = None,\n",
    "    normalize_within_Speciality: bool = True,\n",
    "    patient_id: str = 'pseudo_patient_id',\n",
    "    age_col: str = 'age',\n",
    "    gender_col: str = 'sex',\n",
    "    complexity_col: str = 'Complexity',\n",
    "    acuity_col: str = 'Acuity',\n",
    "    primarydiagnosis_col: str = 'Primary Diagnosis Summary',\n",
    "    department_col: str = 'Speciality',\n",
    "    vitals_col: str = 'Vitals Trend',\n",
    "    waiting_col: str = 'Waiting Time (days)',\n",
    "    admission_col: str = 'Time since Admission (days)',\n",
    "    nextAction_col: str = 'nextAction',\n",
    "    blocker_col: str = 'blocker',\n",
    "    dischargedependence_col: str = 'Discharge Dependence'\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = df.copy()\n",
    "    required = ['Speciality', complexity_col, acuity_col, waiting_col, admission_col, vitals_col]\n",
    "\n",
    "    # Find missing columns\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "\n",
    "    # If any missing, create them with default value 0\n",
    "    for c in missing:\n",
    "        df[c] = 0\n",
    "\n",
    "    # Ensure all expected keys are present (missing keys get 0.0)\n",
    "    for k in ['complexity', 'acuity', 'waiting']:\n",
    "        weights.setdefault(k, 0.0)\n",
    "\n",
    "    w_total = sum(weights.values())\n",
    "    if w_total == 0:\n",
    "        raise ValueError('Sum of weights must be > 0')\n",
    "    weights = {k: v / w_total for k, v in weights.items()}\n",
    "\n",
    "    if vitals_map is None:\n",
    "        vitals_map = DEFAULT_VITALS_ORDER\n",
    "\n",
    "    df['_vitals_score_raw'] = df[vitals_col].map(vitals_map)\n",
    "    if df['_vitals_score_raw'].isna().any():\n",
    "        known_median = df['_vitals_score_raw'].median(skipna=True)\n",
    "        df['_vitals_score_raw'].fillna(known_median, inplace=True)\n",
    "\n",
    "    if normalize_within_Speciality:\n",
    "        norm_complexity = df.groupby('Speciality')[complexity_col].transform(lambda s: normalize_series(s))\n",
    "        norm_acuity = df.groupby('Speciality')[acuity_col].transform(lambda s: normalize_series(s))\n",
    "        norm_wait = df.groupby('Speciality')[waiting_col].transform(lambda s: normalize_series(s))\n",
    "        norm_admit = df.groupby('Speciality')[admission_col].transform(lambda s: normalize_series(s))\n",
    "    else:\n",
    "        norm_complexity = normalize_series(df[complexity_col])\n",
    "        norm_acuity = normalize_series(df[acuity_col])\n",
    "        norm_wait = normalize_series(df[waiting_col])\n",
    "        norm_admit = normalize_series(df[admission_col])\n",
    "\n",
    "    df['_norm_complexity'] = df.groupby('Speciality')[complexity_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "    df['_norm_acuity'] = df.groupby('Speciality')[acuity_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "    df['_norm_wait'] = df.groupby('Speciality')[waiting_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "    df['_norm_admit'] = df.groupby('Speciality')[admission_col].transform(lambda s: normalize_series(s)).fillna(0.5)\n",
    "\n",
    "    df['MCDA_score'] = (\n",
    "        weights['complexity'] * df['_norm_complexity'] +\n",
    "        weights['acuity'] * df['_norm_acuity'] +\n",
    "        weights['vitals'] * df['_vitals_score_raw'] +\n",
    "        weights['waiting'] * df['_norm_wait'] +\n",
    "        weights['admission'] * df['_norm_admit']\n",
    "    )\n",
    "\n",
    "    df['mcda_rank_within_Speciality'] = df.groupby('Speciality')['MCDA_score'].rank(method='first', ascending=False).astype(int)\n",
    "\n",
    "    df['tie_breaker'] = df[[acuity_col, complexity_col, vitals_col]].apply(\n",
    "        lambda row: f\"Acuity={row[acuity_col]}|Complexity={row[complexity_col]}|Vitals={row[vitals_col]}\", axis=1\n",
    "    )\n",
    "\n",
    "    df.drop(columns=['_vitals_score_raw', '_norm_complexity', '_norm_acuity', '_norm_wait', '_norm_admit'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def rank_within_all_specialties(df_out: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame ordered first by Speciality (alphabetical) and then by mcda_rank_within_Speciality.\n",
    "    If you prefer a different Speciality order, reorder 'Speciality' before calling this function.\n",
    "    \"\"\"\n",
    "    df = df_out.copy()\n",
    "    df.sort_values(['Speciality', 'mcda_rank_within_Speciality'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Example usage (run as script or import functions)\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # Load ScenarioA data\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    data_dir = Path('../data/scenarioA/')\n",
    "    paths = {\n",
    "        \"current\": data_dir / \"ScenarioA_patients_current.csv\",\n",
    "        \"coming\": data_dir / \"ScenarioA_patients_coming.csv\",\n",
    "        \"historic\": data_dir / \"ScenarioA_patients_historic.csv\"\n",
    "    }\n",
    "\n",
    "    dfs = {k: pd.read_csv(v) for k, v in paths.items()}\n",
    "    for name, df in dfs.items():\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        dfs[name] = df\n",
    "\n",
    "    current = dfs[\"current\"].copy()\n",
    "    coming = dfs[\"coming\"].copy()\n",
    "    historic = dfs[\"historic\"].copy()\n",
    "\n",
    "    # Choose which dataset to run: 'current', 'coming', or 'historic'\n",
    "    which = 'current'\n",
    "    input_df = dfs[which].copy()\n",
    "\n",
    "    if which == 'current':\n",
    "        weights = {\n",
    "            'complexity': 0.20,\n",
    "            'acuity': 0.30,\n",
    "            'vitals': 0.30,\n",
    "            'waiting': 0.10,\n",
    "            'admission': 0.10\n",
    "        }\n",
    "    elif which == 'coming':\n",
    "        weights = {\n",
    "            'complexity': 0.30,\n",
    "            'acuity': 0.50,\n",
    "            'waiting': 0.20,\n",
    "            'vitals': 0,\n",
    "            'admission':0,\n",
    "        }\n",
    "    # elif which == 'historic':\n",
    "    #     weights = {\n",
    "    #         'complexity': 0.25,\n",
    "    #         'acuity': 0.25,\n",
    "    #         'vitals': 0.25,\n",
    "    #         'waiting': 0.125,\n",
    "    #         'admission': 0.125\n",
    "    #     }\n",
    "\n",
    "    ranked = compute_mcda_scores(input_df, weights=weights, normalize_within_Speciality=True)\n",
    "    ordered = rank_within_all_specialties(ranked)\n",
    "\n",
    "    save_name = f'mcda_ranked_patients_{which}.csv'\n",
    "    ordered.to_csv(save_name, index=False)\n",
    "    print(ordered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1721cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DEFAULT_VITALS_ORDER = {\n",
    "    'Deteriorating': 1.0,\n",
    "    'Stable': 0.5,\n",
    "    'Improving': 0.0\n",
    "}\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def _keyize(name: str) -> str:\n",
    "    \"\"\"Lowercase, strip, collapse spaces/punct to create a matching key.\"\"\"\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    return \"\".join(ch for ch in name.strip().lower() if ch.isalnum())\n",
    "\n",
    "def _apply_column_aliases(df: pd.DataFrame, alias_map: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map many possible input column spellings to canonical names present in alias_map values.\n",
    "    If a canonical column already exists, it is left untouched.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Build lookup from normalized current col names -> actual col name\n",
    "    current = {_keyize(c): c for c in df.columns}\n",
    "\n",
    "    for variants, canonical in alias_map.items():\n",
    "        # variants can be a list/tuple of possible keys\n",
    "        if isinstance(variants, (list, tuple, set)):\n",
    "            found = None\n",
    "            for v in variants:\n",
    "                vkey = _keyize(v)\n",
    "                if vkey in current:\n",
    "                    found = current[vkey]\n",
    "                    break\n",
    "        else:\n",
    "            vkey = _keyize(variants)\n",
    "            found = current.get(vkey, None)\n",
    "\n",
    "        if found is not None and canonical not in df.columns:\n",
    "            df.rename(columns={found: canonical}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def normalize_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Min-max normalize a pandas Series to [0,1]. If constant, returns 0.5 for all; NaNs preserved.\"\"\"\n",
    "    valid = s.dropna()\n",
    "    if valid.empty:\n",
    "        return s\n",
    "    mn = valid.min()\n",
    "    mx = valid.max()\n",
    "    if mn == mx:\n",
    "        out = s.copy()\n",
    "        out.loc[s.notna()] = 0.5\n",
    "        return out\n",
    "    return (s - mn) / (mx - mn)\n",
    "\n",
    "# ---------- Core MCDA ----------\n",
    "def compute_mcda_scores(\n",
    "    df: pd.DataFrame,\n",
    "    weights: Dict[str, float] = None,\n",
    "    vitals_map: Dict[str, float] = None,\n",
    "    normalize_within_Speciality: bool = True,\n",
    "    patient_id: str = 'pseudo_patient_id',\n",
    "    age_col: str = 'age',\n",
    "    gender_col: str = 'sex',\n",
    "    complexity_col: str = 'Complexity',\n",
    "    acuity_col: str = 'Acuity',\n",
    "    primarydiagnosis_col: str = 'Primary Diagnosis Summary',\n",
    "    department_col: str = 'Speciality',\n",
    "    vitals_col: str = 'Vitals Trend',\n",
    "    waiting_col: str = 'Waiting Time (days)',\n",
    "    admission_col: str = 'Time since Admission (days)',\n",
    "    nextAction_col: str = 'nextAction',\n",
    "    blocker_col: str = 'blocker',\n",
    "    dischargedependence_col: str = 'Discharge Dependence'\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # 1) Standardize incoming columns (handles spaces/US-UK spellings/etc.)\n",
    "    alias_map = {\n",
    "        # department\n",
    "        ('speciality', 'specialty', 'department', 'dept'): department_col,\n",
    "        # vitals trend\n",
    "        ('vitalstrend', 'vitals trend', 'vitals', 'trend'): vitals_col,\n",
    "        # waiting days\n",
    "        ('waitingtime(days)', 'waitingtime', 'waitingdays', 'waitdays'): waiting_col,\n",
    "        # admission days\n",
    "        ('timesinceadmission(days)', 'timesinceadmission', 'admissiondays', 'admitdays'): admission_col,\n",
    "        # complexity / acuity\n",
    "        ('complexity',): complexity_col,\n",
    "        ('acuity',): acuity_col,\n",
    "        # others used elsewhere\n",
    "        ('primarydiagnosissummary', 'primarydiagnosis', 'diagnosis', 'dx'): primarydiagnosis_col,\n",
    "        ('dischargedependence', 'discharge dependence'): dischargedependence_col,\n",
    "        ('nextaction',): nextAction_col,\n",
    "        ('blocker', 'block'): blocker_col,\n",
    "        ('sex', 'gender'): gender_col,\n",
    "        ('age',): age_col,\n",
    "        ('pseudopatientid', 'patientid', 'id'): patient_id,\n",
    "    }\n",
    "    df = _apply_column_aliases(df, alias_map)\n",
    "\n",
    "    # 2) Create missing required columns with safe defaults\n",
    "    df = df.copy()\n",
    "    # Required for scoring:\n",
    "    required = [department_col, complexity_col, acuity_col, waiting_col, admission_col, vitals_col]\n",
    "\n",
    "    # Decide defaults by type\n",
    "    default_values: Dict[str, Any] = {\n",
    "        department_col: \"Unknown\",\n",
    "        complexity_col: 0.0,\n",
    "        acuity_col: 0.0,\n",
    "        waiting_col: 0.0,\n",
    "        admission_col: 0.0,\n",
    "        vitals_col: \"Stable\",   # Safe neutral-ish default\n",
    "    }\n",
    "\n",
    "    for c in required:\n",
    "        if c not in df.columns:\n",
    "            df[c] = default_values[c]\n",
    "\n",
    "    # 3) Coerce numeric columns to numeric (errors='coerce' -> NaN -> later filled/handled)\n",
    "    for c in [complexity_col, acuity_col, waiting_col, admission_col]:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # 4) Weights & vitals map defaults\n",
    "    if weights is None:\n",
    "        weights = dict(complexity=0.25, acuity=0.25, vitals=0.25, waiting=0.125, admission=0.125)\n",
    "    # ensure all keys present\n",
    "    for k in ['complexity', 'acuity', 'vitals', 'waiting', 'admission']:\n",
    "        weights.setdefault(k, 0.0)\n",
    "\n",
    "    w_total = sum(weights.values())\n",
    "    if w_total == 0:\n",
    "        # If user gives all zeros, fall back to equal non-zero weights on present criteria\n",
    "        weights = dict(complexity=0.25, acuity=0.25, vitals=0.25, waiting=0.125, admission=0.125)\n",
    "        w_total = 1.0\n",
    "    weights = {k: v / w_total for k, v in weights.items()}\n",
    "\n",
    "    if vitals_map is None:\n",
    "        vitals_map = DEFAULT_VITALS_ORDER\n",
    "\n",
    "    # 5) Vitals mapping -> numeric score, fill unknowns with median of known\n",
    "    df['_vitals_score_raw'] = df[vitals_col].map(vitals_map)\n",
    "    if df['_vitals_score_raw'].isna().any():\n",
    "        known_median = df['_vitals_score_raw'].median(skipna=True)\n",
    "        # If still NaN (e.g., no known), fall back to 0.5\n",
    "        if pd.isna(known_median):\n",
    "            known_median = 0.5\n",
    "        df['_vitals_score_raw'] = df['_vitals_score_raw'].fillna(known_median)\n",
    "\n",
    "    # 6) Normalization (within department or global)\n",
    "    if normalize_within_Speciality:\n",
    "        group = df.groupby(department_col, dropna=False)\n",
    "        norm_complexity = group[complexity_col].transform(normalize_series)\n",
    "        norm_acuity     = group[acuity_col].transform(normalize_series)\n",
    "        norm_wait       = group[waiting_col].transform(normalize_series)\n",
    "        norm_admit      = group[admission_col].transform(normalize_series)\n",
    "    else:\n",
    "        norm_complexity = normalize_series(df[complexity_col])\n",
    "        norm_acuity     = normalize_series(df[acuity_col])\n",
    "        norm_wait       = normalize_series(df[waiting_col])\n",
    "        norm_admit      = normalize_series(df[admission_col])\n",
    "\n",
    "    # Fill NaNs from normalization (e.g., all-NaN/constant groups) with neutral 0.5\n",
    "    df['_norm_complexity'] = norm_complexity.fillna(0.5)\n",
    "    df['_norm_acuity']     = norm_acuity.fillna(0.5)\n",
    "    df['_norm_wait']       = norm_wait.fillna(0.5)\n",
    "    df['_norm_admit']      = norm_admit.fillna(0.5)\n",
    "\n",
    "    # 7) MCDA score\n",
    "    df['MCDA_score'] = (\n",
    "        weights['complexity'] * df['_norm_complexity'] +\n",
    "        weights['acuity']     * df['_norm_acuity'] +\n",
    "        weights['vitals']     * df['_vitals_score_raw'] +\n",
    "        weights['waiting']    * df['_norm_wait'] +\n",
    "        weights['admission']  * df['_norm_admit']\n",
    "    )\n",
    "\n",
    "    # 8) Rank within department\n",
    "    df['mcda_rank_within_Speciality'] = (\n",
    "        df.groupby(department_col)['MCDA_score']\n",
    "          .rank(method='first', ascending=False)\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # 9) Tie-breaker label (robust to missing)\n",
    "    def _fmt_tie(row):\n",
    "        a = row.get(acuity_col, np.nan)\n",
    "        c = row.get(complexity_col, np.nan)\n",
    "        v = row.get(vitals_col, \"Unknown\")\n",
    "        return f\"Acuity={a}|Complexity={c}|Vitals={v}\"\n",
    "\n",
    "    df['tie_breaker'] = df.apply(_fmt_tie, axis=1)\n",
    "\n",
    "    # 10) Cleanup helper cols\n",
    "    df.drop(columns=['_vitals_score_raw', '_norm_complexity', '_norm_acuity', '_norm_wait', '_norm_admit'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def rank_within_all_specialties(df_out: pd.DataFrame, department_col: str = 'Speciality') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame ordered first by department_col (alphabetical)\n",
    "    and then by mcda_rank_within_Speciality.\n",
    "    \"\"\"\n",
    "    df = df_out.copy()\n",
    "    if department_col not in df.columns:\n",
    "        # Graceful fallback\n",
    "        department_col = next((c for c in df.columns if _keyize(c) in ('speciality','specialty','department')), 'Speciality')\n",
    "        if department_col not in df.columns:\n",
    "            df[department_col] = \"Unknown\"\n",
    "    df.sort_values([department_col, 'mcda_rank_within_Speciality'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Example usage\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    from pathlib import Path\n",
    "\n",
    "    data_dir = Path('../data/scenarioA/')\n",
    "    paths = {\n",
    "        \"current\":  data_dir / \"ScenarioA_patients_current.csv\",\n",
    "        \"coming\":   data_dir / \"ScenarioA_patients_coming.csv\",\n",
    "        \"historic\": data_dir / \"ScenarioA_patients_historic.csv\"\n",
    "    }\n",
    "\n",
    "    dfs = {k: pd.read_csv(v) for k, v in paths.items()}\n",
    "\n",
    "    # Trim whitespace in headers\n",
    "    dfs = {k: df.rename(columns={c: c.strip() for c in df.columns}) for k, df in dfs.items()}\n",
    "\n",
    "    which = 'coming'  # 'current' | 'coming' | 'historic'\n",
    "    input_df = dfs[which].copy()\n",
    "\n",
    "    if which == 'current':\n",
    "        weights = {'complexity': 0.20, 'acuity': 0.30, 'vitals': 0.30, 'waiting': 0.10, 'admission': 0.10}\n",
    "    elif which == 'coming':\n",
    "        weights = {'complexity': 0.30, 'acuity': 0.50, 'waiting': 0.20, 'vitals': 0.0, 'admission': 0.0}\n",
    "    else:  # 'historic' or anything else\n",
    "        weights = {'complexity': 0.25, 'acuity': 0.25, 'vitals': 0.25, 'waiting': 0.125, 'admission': 0.125}\n",
    "\n",
    "    ranked = compute_mcda_scores(input_df, weights=weights, normalize_within_Speciality=True)\n",
    "    ordered = rank_within_all_specialties(ranked, department_col='Speciality')\n",
    "\n",
    "    save_name = f'mcda_ranked_patients_{which}.csv'\n",
    "    ordered.to_csv(save_name, index=False)\n",
    "    print(ordered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895fb329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pseudo_patient_id  age sex  Complexity  Acuity Primary Diagnosis Summary  \\\n",
      "0            SP0814    4   F        1.43       4                   K50-K52   \n",
      "1            SP0853   50   F        1.39       4                   K55-K64   \n",
      "2            SP0884   37   F        1.47       5                   K50-K52   \n",
      "3            SP0838   31   F        1.49       5                   K00-K14   \n",
      "4            SP0888   34   F        1.08       5                   K50-K52   \n",
      "5            SP0978   95   F        1.48       5                   K20-K31   \n",
      "6            SP0914   52   F        1.37       5                   K55-K64   \n",
      "7            SP0864   40   M        1.08       5                   K40-K46   \n",
      "8            SP0994   72   F        1.43       4                   K90-K93   \n",
      "9            SP0899   68   F        0.58       4                   K80-K87   \n",
      "\n",
      "          Speciality   Vitals Trend  Waiting Time (days)  \\\n",
      "0  Gastronenterology  Deteriorating                   33   \n",
      "1  Gastronenterology  Deteriorating                    7   \n",
      "2  Gastronenterology         Stable                   95   \n",
      "3  Gastronenterology         Stable                   63   \n",
      "4  Gastronenterology         Stable                    3   \n",
      "5  Gastronenterology            NaN                   29   \n",
      "6  Gastronenterology            NaN                    3   \n",
      "7  Gastronenterology      Improving                   99   \n",
      "8  Gastronenterology            NaN                   10   \n",
      "9  Gastronenterology         Stable                   18   \n",
      "\n",
      "   Time since Admission (days)  nextAction             blocker  \\\n",
      "0                          2.0   Discharge  Staff Availability   \n",
      "1                          1.0      Review          No Blocker   \n",
      "2                          1.0  Assessment    Bed Availability   \n",
      "3                          1.0  Assessment          No Blocker   \n",
      "4                          1.0  Assessment          No Blocker   \n",
      "5                          NaN         NaN                 NaN   \n",
      "6                          NaN         NaN                 NaN   \n",
      "7                          1.0  Assessment          No Blocker   \n",
      "8                          NaN         NaN                 NaN   \n",
      "9                          5.0   Discharge          No Blocker   \n",
      "\n",
      "  Discharge Dependence  Dataset  MCDA_score  mcda_rank_within_Speciality  \\\n",
      "0                  Low  current    0.751991                            1   \n",
      "1                  Low  current    0.718806                            2   \n",
      "2                 High  current    0.702157                            3   \n",
      "3                 High  current    0.691274                            4   \n",
      "4                  Low  current    0.576656                            5   \n",
      "5                  Low   coming    0.560631                            6   \n",
      "6                  Low   coming    0.525209                            7   \n",
      "7                  Low  current    0.471939                            8   \n",
      "8                 High   coming    0.466142                            9   \n",
      "9                  Low  current    0.453468                           10   \n",
      "\n",
      "                                     tie_breaker  overall_rank  \n",
      "0  Acuity=4|Complexity=1.43|Vitals=Deteriorating             3  \n",
      "1  Acuity=4|Complexity=1.39|Vitals=Deteriorating             7  \n",
      "2         Acuity=5|Complexity=1.47|Vitals=Stable             8  \n",
      "3         Acuity=5|Complexity=1.49|Vitals=Stable             9  \n",
      "4         Acuity=5|Complexity=1.08|Vitals=Stable            21  \n",
      "5            Acuity=5|Complexity=1.48|Vitals=nan            24  \n",
      "6            Acuity=5|Complexity=1.37|Vitals=nan            32  \n",
      "7      Acuity=5|Complexity=1.08|Vitals=Improving            54  \n",
      "8            Acuity=4|Complexity=1.43|Vitals=nan            57  \n",
      "9         Acuity=4|Complexity=0.58|Vitals=Stable            67  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Example usage (combine current + coming and rank)\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    data_dir = Path('../data/scenarioA/')\n",
    "    paths = {\n",
    "        \"current\":  data_dir / \"ScenarioA_patients_current.csv\",\n",
    "        \"coming\":   data_dir / \"ScenarioA_patients_coming.csv\",\n",
    "    }\n",
    "\n",
    "    # Load & trim header whitespace\n",
    "    dfs = {}\n",
    "    for name, p in paths.items():\n",
    "        df = pd.read_csv(p)\n",
    "        df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "        df[\"Dataset\"] = name  # tag source\n",
    "        dfs[name] = df\n",
    "\n",
    "    # Combine current + coming\n",
    "    input_df = pd.concat([dfs[\"current\"], dfs[\"coming\"]], ignore_index=True)\n",
    "\n",
    "    # Choose unified weights for the combined list\n",
    "    # (you can tweak these; using the more \"current\"-like set)\n",
    "    weights = {\n",
    "        'complexity': 0.20,\n",
    "        'acuity':     0.30,\n",
    "        'vitals':     0.30,  # rows without vitals will auto-fill neutrals\n",
    "        'waiting':    0.10,\n",
    "        'admission':  0.10\n",
    "    }\n",
    "\n",
    "    ranked = compute_mcda_scores(\n",
    "        input_df,\n",
    "        weights=weights,\n",
    "        normalize_within_Speciality=True,   # normalize per Speciality\n",
    "        department_col='Speciality',\n",
    "        vitals_col='Vitals Trend',\n",
    "        complexity_col='Complexity',\n",
    "        acuity_col='Acuity',\n",
    "        waiting_col='Waiting Time (days)',\n",
    "        admission_col='Time since Admission (days)'\n",
    "    )\n",
    "\n",
    "    # Order by Speciality then MCDA rank (combined across current+coming)\n",
    "    ordered = rank_within_all_specialties(ranked, department_col='Speciality')\n",
    "\n",
    "    # Also add an overall priority rank (ignoring Speciality) if you want\n",
    "    ordered['overall_rank'] = ordered['MCDA_score'].rank(method='first', ascending=False).astype(int)\n",
    "\n",
    "    # Save results\n",
    "    ordered.to_csv('mcda_ranked_patients_current_plus_coming.csv', index=False)\n",
    "    print(ordered.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a39f9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'mcda_ranked_patients_current_plus_coming.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Save to file\u001b[39;00m\n\u001b[0;32m     53\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcda_ranked_patients_current_plus_coming.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mordered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Combined ranking saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Show preview\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3978\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3980\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3981\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3982\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3986\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3987\u001b[0m )\n\u001b[1;32m-> 3989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4006\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\xinwe\\miniconda3\\envs\\tkinter\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'mcda_ranked_patients_current_plus_coming.csv'"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Example usage (combine current + coming with source label)\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    data_dir = Path('../data/scenarioA/')\n",
    "    paths = {\n",
    "        \"current\":  data_dir / \"ScenarioA_patients_current.csv\",\n",
    "        \"coming\":   data_dir / \"ScenarioA_patients_coming.csv\",\n",
    "    }\n",
    "\n",
    "    dfs = {}\n",
    "    for name, p in paths.items():\n",
    "        df = pd.read_csv(p)\n",
    "        df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "        df[\"Dataset\"] = name  # add source label column\n",
    "        dfs[name] = df\n",
    "\n",
    "    # Combine current + coming into one DataFrame\n",
    "    combined_df = pd.concat([dfs[\"current\"], dfs[\"coming\"]], ignore_index=True)\n",
    "\n",
    "    # Unified weight configuration\n",
    "    weights = {\n",
    "        'complexity': 0.25,\n",
    "        'acuity':     0.35,\n",
    "        'vitals':     0.25,  # some 'coming' patients may have no vitals → handled automatically\n",
    "        'waiting':    0.10,\n",
    "        'admission':  0.05\n",
    "    }\n",
    "\n",
    "    # Compute MCDA scores for the combined data\n",
    "    ranked = compute_mcda_scores(\n",
    "        combined_df,\n",
    "        weights=weights,\n",
    "        normalize_within_Speciality=True,\n",
    "        department_col='Speciality',\n",
    "        vitals_col='Vitals Trend',\n",
    "        complexity_col='Complexity',\n",
    "        acuity_col='Acuity',\n",
    "        waiting_col='Waiting Time (days)',\n",
    "        admission_col='Time since Admission (days)'\n",
    "    )\n",
    "\n",
    "    # Rank within each Speciality\n",
    "    ordered = rank_within_all_specialties(ranked, department_col='Speciality')\n",
    "\n",
    "    # Add an overall rank across all Specialities (optional)\n",
    "    ordered['overall_rank'] = ordered['MCDA_score'].rank(method='first', ascending=False).astype(int)\n",
    "\n",
    "    # Save to file\n",
    "    save_path = 'mcda_ranked_patients_current_plus_coming.csv'\n",
    "    ordered.to_csv(save_path, index=False)\n",
    "    print(f\"✅ Combined ranking saved to {save_path}\")\n",
    "\n",
    "    # Show preview\n",
    "    print(ordered[['pseudo_patient_id', 'Speciality', 'MCDA_score',\n",
    "                   'mcda_rank_within_Speciality', 'overall_rank', 'Dataset']].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tkinter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
